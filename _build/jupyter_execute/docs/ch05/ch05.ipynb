{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第5章: 大規模言語モデル\n",
    "\n",
    "この章では, 大規模言語モデル (LLM; Large Language Model) の利用し, 様々なタスクに取り組む. 大規模言語モデルをプログラムからAPI経由で呼び出すことを想定しており, そのAPIの利用で費用が発生する可能性があることに留意せよ.\n",
    "\n",
    "```{warning}\n",
    "本章は, `code-cell` ではなく, Markdown のコードブロック内にコードを記述しているため, Google Colab上で直接実行できません.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install vllm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 40. Zero-Shot推論\n",
    "\n",
    "以下の問題の解答を作成せよ. ただし, 解答生成はzero-shot推論とせよ.\n",
    "\n",
    "```\n",
    "9世紀に活躍した人物に関係するできごとについて述べた次のア～ウを年代の古い順に正しく並べよ。\n",
    "\n",
    "ア　藤原時平は，策謀を用いて菅原道真を政界から追放した。\n",
    "イ　嵯峨天皇は，藤原冬嗣らを蔵人頭に任命した。\n",
    "ウ　藤原良房は，承和の変後，藤原氏の中での北家の優位を確立した。\n",
    "```\n",
    "\n",
    "出典: [令和5年度第1回高等学校卒業程度認定試験問題](https://www.mext.go.jp/a_menu/koutou/shiken/kakomon/1411255_00010.htm) [日本史AB](https://www.mext.go.jp/content/20240523-mxt_syogai02-mext_000031286_03nihonshi.pdf) 問題 日本史B 1 問3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from transformers import AutoTokenizer\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "model_name = \"tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "llm = LLM(\n",
    "    model=model_name,\n",
    "    tensor_parallel_size=1,\n",
    "    dtype=\"float16\"\n",
    ")\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0.6, top_p=0.9, max_tokens=512, stop=\"<|eot_id|>\"\n",
    ")\n",
    "\n",
    "system_prompt = {\n",
    "    \"role\": \"system\", \n",
    "    \"content\": \"あなたは日本の歴史学者です。\"\n",
    "}\n",
    "\n",
    "user_prompt = \"\"\"9世紀に活躍した人物に関係するできごとについて述べた次のア～ウを年代の古い順に正しく並べよ。\n",
    "\n",
    "ア　藤原時平は，策謀を用いて菅原道真を政界から追放した。\n",
    "イ　嵯峨天皇は，藤原冬嗣らを蔵人頭に任命した。\n",
    "ウ　藤原良房は，承和の変後，藤原氏の中での北家の優位を確立した。\"\"\"\n",
    "\n",
    "message = [\n",
    "    system_prompt,\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    message, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "outputs = llm.generate(prompt, sampling_params)\n",
    "result = outputs[0].outputs[0].text.strip()\n",
    "\n",
    "print(\"解答:\", result)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "解答: 正しい年代の古い順に並べると次のようになります。\n",
    "\n",
    "1. **イ　嵯峨天皇は，藤原冬嗣らを蔵人頭に任命した。** (809年)\n",
    "2. **ウ　藤原良房は，承和の変後，藤原氏の中での北家の優位を確立した。** (842年)\n",
    "3. **ア　藤原時平は，策謀を用いて菅原道真を政界から追放した。** (903年)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 41. Few-Shot推論\n",
    "\n",
    "以下の問題と解答を与え, 問題40で示した質問の解答をfew-shot推論（この場合は4-shot推論）で生成せよ.\n",
    "\n",
    "```\n",
    "日本の近代化に関連するできごとについて述べた次のア～ウを年代の古い順に正しく並べよ。\n",
    "\n",
    "ア　府知事・県令からなる地方官会議が設置された。\n",
    "イ　廃藩置県が実施され，中央から府知事・県令が派遣される体制になった。\n",
    "ウ　すべての藩主が，天皇に領地と領民を返還した。\n",
    "\n",
    "解答: ウ→イ→ア\n",
    "```\n",
    "\n",
    "出典: [令和5年度第1回高等学校卒業程度認定試験問題](https://www.mext.go.jp/a_menu/koutou/shiken/kakomon/1411255_00010.htm) [日本史AB 問題](https://www.mext.go.jp/content/20240523-mxt_syogai02-mext_000031286_03nihonshi.pdf) 日本史A 1 問8\n",
    "\n",
    "```\n",
    "江戸幕府の北方での対外的な緊張について述べた次の文ア～ウを年代の古い順に正しく並べよ。\n",
    "\n",
    "ア　レザノフが長崎に来航したが，幕府が冷淡な対応をしたため，ロシア船が樺太や択捉島を攻撃した。\n",
    "イ　ゴローウニンが国後島に上陸し，幕府の役人に捕らえられ抑留された。\n",
    "ウ　ラクスマンが根室に来航し，漂流民を届けるとともに通商を求めた。\n",
    "\n",
    "解答: ウ→ア→イ\n",
    "```\n",
    "\n",
    "出典: [令和5年度第1回高等学校卒業程度認定試験問題](https://www.mext.go.jp/a_menu/koutou/shiken/kakomon/1411255_00010.htm) [日本史AB 問題](https://www.mext.go.jp/content/20240523-mxt_syogai02-mext_000031286_03nihonshi.pdf) 日本史B 3 問3\n",
    "\n",
    "```\n",
    "中居屋重兵衛の生涯の期間におこったできごとについて述べた次のア～ウを，年代の古い順に正しく並べよ。\n",
    "\n",
    "ア　アヘン戦争がおこり，清がイギリスに敗北した。\n",
    "イ　異国船打払令が出され，外国船を撃退することが命じられた。\n",
    "ウ　桜田門外の変がおこり，大老の井伊直弼が暗殺された。\n",
    "\n",
    "解答: イ→ア→ウ\n",
    "```\n",
    "\n",
    "出典: [令和4年度第1回高等学校卒業程度認定試験問題](https://www.mext.go.jp/a_menu/koutou/shiken/kakomon/1411255_00007.htm) [日本史 問題](https://www.mext.go.jp/content/20240513-mxt_syogai02-mext_00002452_03nihonshi.pdf) 日本史A 1 問1\n",
    "\n",
    "```\n",
    "加藤高明が外務大臣として提言を行ってから、内閣総理大臣となり演説を行うまでの時期のできごとについて述べた次のア～ウを，年代の古い順に正しく並べよ。\n",
    "\n",
    "ア　朝鮮半島において，独立を求める大衆運動である三・一独立運動が展開された。\n",
    "イ　関東大震災後の混乱のなかで，朝鮮人や中国人に対する殺傷事件がおきた。\n",
    "ウ　日本政府が，袁世凱政府に対して二十一カ条の要求を突き付けた。\n",
    "\n",
    "解答: ウ→ア→イ\n",
    "```\n",
    "\n",
    "出典: [令和4年度第1回高等学校卒業程度認定試験問題](https://www.mext.go.jp/a_menu/koutou/shiken/kakomon/1411255_00007.htm) [日本史 問題](https://www.mext.go.jp/content/20240513-mxt_syogai02-mext_00002452_03nihonshi.pdf) 日本史A 2 問4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from transformers import AutoTokenizer\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "model_name = \"tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "llm = LLM(\n",
    "    model=model_name,\n",
    "    tensor_parallel_size=1,\n",
    "    dtype=\"float16\"\n",
    ")\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0.6, top_p=0.9, max_tokens=512, stop=\"<|eot_id|>\"\n",
    ")\n",
    "\n",
    "system_prompt = {\n",
    "    \"role\": \"system\", \n",
    "    \"content\": \"あなたは日本の歴史学者です。\"\n",
    "}\n",
    "\n",
    "fewshot_prompt = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"日本の近代化に関連するできごとについて述べた次のア～ウを年代の古い順に正しく並べよ。\n",
    "\n",
    "ア　府知事・県令からなる地方官会議が設置された。\n",
    "イ　廃藩置県が実施され，中央から府知事・県令が派遣される体制になった。\n",
    "ウ　すべての藩主が，天皇に領地と領民を返還した。\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"ウ→イ→ア\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"江戸幕府の北方での対外的な緊張について述べた次の文ア～ウを年代の古い順に正しく並べよ。\n",
    "\n",
    "ア　レザノフが長崎に来航したが，幕府が冷淡な対応をしたため，ロシア船が樺太や択捉島を攻撃した。\n",
    "イ　ゴローウニンが国後島に上陸し，幕府の役人に捕らえられ抑留された。\n",
    "ウ　ラクスマンが根室に来航し，漂流民を届けるとともに通商を求めた。\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"ウ→ア→イ\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"中居屋重兵衛の生涯の期間におこったできごとについて述べた次のア～ウを，年代の古い順に正しく並べよ。\n",
    "\n",
    "ア　アヘン戦争がおこり，清がイギリスに敗北した。\n",
    "イ　異国船打払令が出され，外国船を撃退することが命じられた。\n",
    "ウ　桜田門外の変がおこり，大老の井伊直弼が暗殺された。\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"イ→ア→ウ\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"加藤高明が外務大臣として提言を行ってから、内閣総理大臣となり演説を行うまでの時期のできごとについて述べた次のア～ウを，年代の古い順に正しく並べよ。\n",
    "\n",
    "ア　朝鮮半島において，独立を求める大衆運動である三・一独立運動が展開された。\n",
    "イ　関東大震災後の混乱のなかで，朝鮮人や中国人に対する殺傷事件がおきた。\n",
    "ウ　日本政府が，袁世凱政府に対して二十一カ条の要求を突き付けた。\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"ウ→ア→イ\"\n",
    "    }\n",
    "]\n",
    "\n",
    "user_prompt = \"\"\"9世紀に活躍した人物に関係するできごとについて述べた次のア～ウを年代の古い順に正しく並べよ。\n",
    "\n",
    "ア　藤原時平は，策謀を用いて菅原道真を政界から追放した。\n",
    "イ　嵯峨天皇は，藤原冬嗣らを蔵人頭に任命した。\n",
    "ウ　藤原良房は，承和の変後，藤原氏の中での北家の優位を確立した。\"\"\"\n",
    "\n",
    "message = [\n",
    "    system_prompt,\n",
    "    *fewshot_prompt,\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    message, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "outputs = llm.generate(prompt, sampling_params)\n",
    "result = outputs[0].outputs[0].text.strip()\n",
    "\n",
    "print(\"解答:\", result)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "解答: イ→ウ→ア\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 42. 多肢選択問題の正解率\n",
    "\n",
    "[JMMLU](https://github.com/nlp-waseda/JMMLU) のいずれかの科目を大規模言語モデルに解答させ, その正解率を求めよ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/nlp-waseda/JMMLU.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "df = pd.read_csv(\"JMMLU/JMMLU/abstract_algebra.csv\", header=None)\n",
    "df.columns = [\"question\", \"selA\", \"selB\", \"selC\", \"selD\", \"answer\"]\n",
    "\n",
    "model_name = \"tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "llm = LLM(\n",
    "    model=model_name,\n",
    "    tensor_parallel_size=1,\n",
    "    dtype=\"float16\", \n",
    ")\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0.6, top_p=0.9, max_tokens=512, stop=\"<|eot_id|>\"\n",
    ")\n",
    "\n",
    "system_prompt = {\n",
    "    \"role\": \"system\", \n",
    "    \"content\": \"あなたは優れた抽象代数学の専門家です。以下の質問に対して所与の選択肢から正しい答えを選んでください。そのため、解答として許容される文字は「A」「B」「C」「D」のみです。解答は選択肢のいずれか1つを選ぶ形で行ってください。\"\n",
    "}\n",
    "\n",
    "valid_answers = ['A', 'B', 'C', 'D']\n",
    "predictions = []\n",
    "invalid_cnt = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    question_text = row[\"question\"] + \"\\n\" + f\"A: {row['selA']} B: {row['selB']} C: {row['selC']} D: {row['selD']}\"\n",
    "    \n",
    "    user_prompt = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": question_text\n",
    "    }\n",
    "\n",
    "    message = [system_prompt, user_prompt]\n",
    "    \n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        message, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    answer = llm.generate(prompt, sampling_params)\n",
    "    answer = answer[0].outputs[0].text.strip()\n",
    "\n",
    "    if answer not in valid_answers:\n",
    "        clarification_prompt = [\n",
    "            system_prompt,\n",
    "            user_prompt,\n",
    "            {\"role\": \"assistant\", \"content\": answer},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    f\"あなたの先ほどの回答「{answer}」はラベル (A/B/C/D) のいずれでもありません。\"\n",
    "                    \"これは選択肢のどれに該当するか、ラベル (A/B/C/D) のみで1文字で答えてください。\"\n",
    "                )\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        clarification_text = tokenizer.apply_chat_template(\n",
    "            clarification_prompt, tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "\n",
    "        clarification_answers = llm.generate(clarification_text, sampling_params)\n",
    "        clarified_answer = clarification_answers[0].outputs[0].text.strip().upper()\n",
    "\n",
    "        if clarified_answer in valid_answers:\n",
    "            answer = clarified_answer\n",
    "        else:\n",
    "            answer = \"Invalid\"\n",
    "            invalid_cnt += 1\n",
    "\n",
    "    predictions.append(answer)\n",
    "    \n",
    "valid_indices = [i for i, p in enumerate(predictions) if p in valid_answers]\n",
    "correct_predictions = [\n",
    "    predictions[i] == df.loc[i, 'answer']\n",
    "    for i in valid_indices\n",
    "]\n",
    "\n",
    "accuracy = sum(correct_predictions) / len(correct_predictions) if correct_predictions else 0.0\n",
    "print(f\"\\nAccurasy: {accuracy * 100:.2f}% (Number of invalid predictions: {invalid_cnt})\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "Accurasy: 31.96% (Number of invalid predictions: 2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 43. 応答のバイアス\n",
    "\n",
    "問題42において, 実験設定を変化させると正解率が変化するかどうかを調べよ. 実験設定の例としては, 大規模言語モデルの温度パラメータ, プロンプト, 多肢選択肢の順番, 多肢選択肢の記号などが考えられる."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "df = pd.read_csv(\"JMMLU/JMMLU/abstract_algebra.csv\", header=None)\n",
    "df.columns = [\"question\", \"selA\", \"selB\", \"selC\", \"selD\", \"answer\"]\n",
    "\n",
    "model_name = \"tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "llm = LLM(\n",
    "    model=model_name,\n",
    "    tensor_parallel_size=1,\n",
    "    dtype=\"float16\", \n",
    ")\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0.6, top_p=0.9, max_tokens=512, stop=\"<|eot_id|>\"\n",
    ")\n",
    "\n",
    "system_prompt = {\n",
    "    \"role\": \"system\", \n",
    "    \"content\": \"あなたは優れた抽象代数学の専門家です。以下の質問に対して所与の選択肢から正しい答えを選んでください。そのため、解答として許容される文字は「A」「B」「C」「D」のみです。解答は選択肢のいずれか1つを選ぶ形で行ってください。\"\n",
    "}\n",
    "\n",
    "valid_answers = ['A', 'B', 'C', 'D']\n",
    "predictions = []\n",
    "invalid_cnt = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    question_text = {\n",
    "        \"question\": row[\"question\"],\n",
    "        \"options\": {\n",
    "            \"A\": row[\"selA\"],\n",
    "            \"B\": row[\"selB\"],\n",
    "            \"C\": row[\"selC\"],\n",
    "            \"D\": row[\"selD\"]\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    user_prompt = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": question_text\n",
    "    }\n",
    "\n",
    "    message = [system_prompt, user_prompt]\n",
    "    \n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        message, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    answer = llm.generate(prompt, sampling_params)\n",
    "    answer = answer[0].outputs[0].text.strip()\n",
    "\n",
    "    if answer not in valid_answers:\n",
    "        clarification_prompt = [\n",
    "            system_prompt,\n",
    "            user_prompt,\n",
    "            {\"role\": \"assistant\", \"content\": answer},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    f\"あなたの先ほどの解答「{answer}」はラベル (A/B/C/D) のいずれでもありません。\"\n",
    "                    \"これは選択肢のどれに該当するか、ラベル (A/B/C/D) のみで1文字で答えてください。\"\n",
    "                )\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        clarification_text = tokenizer.apply_chat_template(\n",
    "            clarification_prompt, tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "\n",
    "        clarification_answers = llm.generate(clarification_text, sampling_params)\n",
    "        clarified_answer = clarification_answers[0].outputs[0].text.strip().upper()\n",
    "\n",
    "        if clarified_answer in valid_answers:\n",
    "            answer = clarified_answer\n",
    "        else:\n",
    "            answer = \"Invalid\"\n",
    "            invalid_cnt += 1\n",
    "\n",
    "    predictions.append(answer)\n",
    "    \n",
    "valid_indices = [i for i, p in enumerate(predictions) if p in valid_answers]\n",
    "correct_predictions = [\n",
    "    predictions[i] == df.loc[i, 'answer']\n",
    "    for i in valid_indices\n",
    "]\n",
    "\n",
    "accuracy = sum(correct_predictions) / len(correct_predictions) if correct_predictions else 0.0\n",
    "print(f\"\\nAccurasy: {accuracy * 100:.2f}% (Number of invalid predictions: {invalid_cnt})\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "Accurasy: 37.76% (Number of invalid predictions: 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 44. 対話\n",
    "\n",
    "以下の問いかけに対する応答を生成せよ.\n",
    "\n",
    "> つばめちゃんは渋谷駅から東急東横線に乗り、自由が丘駅で乗り換えました。東急大井町線の大井町方面の電車に乗り換えたとき、各駅停車に乗車すべきところ、間違えて急行に乗車してしまったことに気付きました。自由が丘の次の急行停車駅で降車し、反対方向の電車で一駅戻った駅がつばめちゃんの目的地でした。目的地の駅の名前を答えてください。\n",
    "\n",
    "参考: [東急線・みなとみらい線路線案内](https://www.tokyu.co.jp/railway/station/map.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from transformers import AutoTokenizer\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "model_name = \"tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "llm = LLM(\n",
    "    model=model_name,\n",
    "    tensor_parallel_size=1,\n",
    "    dtype=\"float16\"\n",
    ")\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0.6, top_p=0.9, max_tokens=512, stop=\"<|eot_id|>\"\n",
    ")\n",
    "\n",
    "system_prompt = {\n",
    "    \"role\": \"system\", \n",
    "    \"content\": \"あなたは日本の鉄道員です。\"\n",
    "}\n",
    "\n",
    "user_prompt = \"つばめちゃんは渋谷駅から東急東横線に乗り、自由が丘駅で乗り換えました。東急大井町線の大井町方面の電車に乗り換えたとき、各駅停車に乗車すべきところ、間違えて急行に乗車してしまったことに気付きました。自由が丘の次の急行停車駅で降車し、反対方向の電車で一駅戻った駅がつばめちゃんの目的地でした。目的地の駅の名前を答えてください。\"\n",
    "\n",
    "message = [\n",
    "    system_prompt,\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    message, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "outputs = llm.generate(prompt, sampling_params)\n",
    "result = outputs[0].outputs[0].text.strip()\n",
    "\n",
    "print(\"解答:\", result)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "解答: つばめちゃんの目的地は **緑が丘駅** です。\n",
    "\n",
    "東急東横線と東急大井町線は、自由が丘駅で接続しています。東急大井町線の急行は、自由が丘駅から次の停車駅である **緑が丘駅** に止まります。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 45. マルチターン対話\n",
    "\n",
    "先ほどの応答に続けて, 以下の追加の問いかけに対する応答を生成せよ.\n",
    "\n",
    "> さらに、つばめちゃんが自由が丘駅で乗り換えたとき、先ほどとは反対方向の急行電車に間違って乗車してしまった場合を考えます。目的地の駅に向かうため、自由が丘の次の急行停車駅で降車した後、反対方向の各駅停車に乗車した場合、何駅先の駅で降りれば良いでしょうか？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "from transformers import AutoTokenizer\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "model_name = \"tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "llm = LLM(\n",
    "    model=model_name,\n",
    "    tensor_parallel_size=1,\n",
    "    dtype=\"float16\"\n",
    ")\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0.6, top_p=0.9, max_tokens=512, stop=\"<|eot_id|>\"\n",
    ")\n",
    "\n",
    "system_prompt = {\n",
    "    \"role\": \"system\", \n",
    "    \"content\": \"あなたは日本の鉄道員です。\"\n",
    "}\n",
    "\n",
    "user_prompts = [\n",
    "    \"つばめちゃんは渋谷駅から東急東横線に乗り、自由が丘駅で乗り換えました。東急大井町線の大井町方面の電車に乗り換えたとき、各駅停車に乗車すべきところ、間違えて急行に乗車してしまったことに気付きました。自由が丘の次の急行停車駅で降車し、反対方向の電車で一駅戻った駅がつばめちゃんの目的地でした。目的地の駅の名前を答えてください。\",\n",
    "    \"さらに、つばめちゃんが自由が丘駅で乗り換えたとき、先ほどとは反対方向の急行電車に間違って乗車してしまった場合を考えます。目的地の駅に向かうため、自由が丘の次の急行停車駅で降車した後、反対方向の各駅停車に乗車した場合、何駅先の駅で降りれば良いでしょうか？\"\n",
    "]\n",
    "\n",
    "message = [\n",
    "    system_prompt,\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_prompts[0]\n",
    "    }\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    message, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "outputs1 = llm.generate(prompt, sampling_params)\n",
    "result1 = outputs1[0].outputs[0].text.strip()\n",
    "\n",
    "message = [\n",
    "    system_prompt,\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_prompts[0]\n",
    "    }\n",
    "]\n",
    "\n",
    "message.append({\"role\": \"assistant\", \"content\": result1})\n",
    "message.append({\"role\": \"user\", \"content\": user_prompts[1]})\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    message, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "outputs2 = llm.generate(prompt, sampling_params)\n",
    "result2 = outputs2[0].outputs[0].text.strip()\n",
    "\n",
    "print(\"解答:\", result2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "解答: つばめちゃんは自由が丘駅で乗り換えた後、反対方向の急行に乗車してしまい、自由が丘の次の急行停車駅で降車しました。\n",
    "\n",
    "つばめちゃんの目的地は緑が丘駅なので、反対方向の各駅停車に乗車して、 **1駅** 先の駅で降りれば良いでしょう。\n",
    "\n",
    "緑が丘駅は、自由が丘駅から東急大井町線で **1駅** 先にあります。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 46. 川柳の生成\n",
    "\n",
    "適当なお題を設定し, 川柳の案を10個作成せよ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from transformers import AutoTokenizer\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "model_name = \"tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "llm = LLM(\n",
    "    model=model_name,\n",
    "    tensor_parallel_size=1,\n",
    "    dtype=\"float16\"\n",
    ")\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0.6, top_p=0.9, max_tokens=512, stop=\"<|eot_id|>\"\n",
    ")\n",
    "\n",
    "system_prompt = {\n",
    "    \"role\": \"system\", \n",
    "    \"content\": \"あなたは日本の川柳家です。\"\n",
    "}\n",
    "\n",
    "user_prompt = \"「春」をお題として川柳を10句作ってください。\"\n",
    "\n",
    "message = [\n",
    "    system_prompt,\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    message, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "outputs = llm.generate(prompt, sampling_params)\n",
    "result = outputs[0].outputs[0].text.strip()\n",
    "\n",
    "print(\"解答:\", result)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "解答: ## 春の川柳\n",
    "\n",
    "1.  桜舞う　風に誘われて　花見行く\n",
    "2.  鳥のさえずり　朝の光に　春を告げる\n",
    "3.  雪解け水　田んぼに湧き　命の息吹\n",
    "4.  芽吹き出す　緑の葉　春の息吹\n",
    "5.  夕暮れ時　茜色に染まる　春の空\n",
    "6.  雲一つ　浮かぶ青空　春の始まり\n",
    "7.  温かい日差し　心も軽く　笑顔が溢れる\n",
    "8.  雪解け水　小川の流れ　春を運ぶ\n",
    "9.  花々咲き　世界は彩り　春の魔法\n",
    "10. 春の息吹　新しい始まり　希望に満ちて\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 47. LLMによる評価\n",
    "\n",
    "大規模言語モデルを評価者 (ジャッジ) として, 問題46の川柳の面白さを10段階で評価せよ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from transformers import AutoTokenizer\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "model_name = \"tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "llm = LLM(\n",
    "    model=model_name,\n",
    "    tensor_parallel_size=1,\n",
    "    dtype=\"float16\"\n",
    ")\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0.6, top_p=0.9, max_tokens=1024, stop=\"<|eot_id|>\"\n",
    ")\n",
    "\n",
    "system_prompt = {\n",
    "    \"role\": \"system\",   \n",
    "    \"content\": \"あなたは日本の川柳評論家です。以下に、「春」をお題とした川柳を示します。その川柳の面白さを1～10の10段階で評価してください。ただし、許容される出力は「1」から「10」までの整数値のみです。すなわち、出力可能トークン数は1です。\"\n",
    "}\n",
    "\n",
    "senryu_examples = [\n",
    "    \"桜舞う　風に誘われて　花見行く\",\n",
    "    \"鳥のさえずり　朝の光に　春を告げる\",\n",
    "    \"雪解け水　田んぼに湧き　命の息吹\",\n",
    "    \"芽吹き出す　緑の葉　春の息吹\",\n",
    "    \"夕暮れ時　茜色に染まる　春の空\",\n",
    "    \"雲一つ　浮かぶ青空　春の始まり\",\n",
    "    \"温かい日差し　心も軽く　笑顔が溢れる\",\n",
    "    \"雪解け水　小川の流れ　春を運ぶ\",\n",
    "    \"花々咲き　世界は彩り　春の魔法\",\n",
    "    \"春の息吹　新しい始まり　希望に満ちて\"\n",
    "]\n",
    "\n",
    "user_prompt = []\n",
    "scores = []\n",
    "for senryu in senryu_examples:\n",
    "    user_prompt = {\"role\": \"user\", \"content\": senryu}\n",
    "    \n",
    "    message = [system_prompt, user_prompt]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        message, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    outputs = llm.generate(prompt, sampling_params)\n",
    "    result = outputs[0].outputs[0].text.strip()\n",
    "    \n",
    "    scores += result\n",
    "    \n",
    "for senryu, score in zip(senryu_examples, scores):\n",
    "    print(f\"川柳: {senryu}\")\n",
    "    print(f\"評価: {score}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "川柳: 桜舞う　風に誘われて　花見行く\n",
    "評価: 7\n",
    "川柳: 鳥のさえずり　朝の光に　春を告げる\n",
    "評価: 7\n",
    "川柳: 雪解け水　田んぼに湧き　命の息吹\n",
    "評価: 8\n",
    "川柳: 芽吹き出す　緑の葉　春の息吹\n",
    "評価: 8\n",
    "川柳: 夕暮れ時　茜色に染まる　春の空\n",
    "評価: 7\n",
    "川柳: 雲一つ　浮かぶ青空　春の始まり\n",
    "評価: 7\n",
    "川柳: 温かい日差し　心も軽く　笑顔が溢れる\n",
    "評価: 8\n",
    "川柳: 雪解け水　小川の流れ　春を運ぶ\n",
    "評価: 8\n",
    "川柳: 花々咲き　世界は彩り　春の魔法\n",
    "評価: 7\n",
    "川柳: 春の息吹　新しい始まり　希望に満ちて\n",
    "評価: 7\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 48. LLMによる評価の頑健性\n",
    "\n",
    "問題47で行ったLLMによるテキストの評価に関して, その頑健さ (脆弱さ) を調査せよ. 最も単純な方法は, 同じ評価を何回か繰り返した時のスコアの分散を調べることであろう. また, 川柳の末尾に特定のメッセージを追加することで, 評価スコアを恣意的に操作することも可能であろう."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 49. トークン化\n",
    "\n",
    "以下の文章 (夏目漱石の『吾輩は猫である』の冒頭部分) のトークン数を計測せよ.\n",
    "\n",
    "> 吾輩は猫である。名前はまだ無い。\n",
    ">\n",
    ">どこで生れたかとんと見当がつかぬ。何でも薄暗いじめじめした所でニャーニャー泣いていた事だけは記憶している。吾輩はここで始めて人間というものを見た。しかもあとで聞くとそれは書生という人間中で一番獰悪な種族であったそうだ。この書生というのは時々我々を捕えて煮て食うという話である。しかしその当時は何という考もなかったから別段恐しいとも思わなかった。ただ彼の掌に載せられてスーと持ち上げられた時何だかフワフワした感じがあったばかりである。掌の上で少し落ちついて書生の顔を見たのがいわゆる人間というものの見始であろう。この時妙なものだと思った感じが今でも残っている。第一毛をもって装飾されべきはずの顔がつるつるしてまるで薬缶だ。その後猫にもだいぶ逢ったがこんな片輪には一度も出会わした事がない。のみならず顔の真中があまりに突起している。そうしてその穴の中から時々ぷうぷうと煙を吹く。どうも咽せぽくて実に弱った。これが人間の飲む煙草というものである事はようやくこの頃知った。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from transformers import AutoTokenizer\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "model_name = \"tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "llm = LLM(\n",
    "    model=model_name,\n",
    "    tensor_parallel_size=1,\n",
    "    dtype=\"float16\"\n",
    ")\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0.6, top_p=0.9, max_tokens=512, stop=\"<|eot_id|>\"\n",
    ")\n",
    "\n",
    "system_prompt = {\n",
    "    \"role\": \"system\",   \n",
    "    \"content\": \"あなたは日本の文章校正者です。以下に示す文章のトークン数を計測してください。\"\n",
    "}\n",
    "\n",
    "nekodearu = \"\"\"吾輩は猫である。名前はまだ無い。\n",
    "\n",
    "どこで生れたかとんと見当がつかぬ。何でも薄暗いじめじめした所でニャーニャー泣いていた事だけは記憶している。吾輩はここで始めて人間というものを見た。しかもあとで聞くとそれは書生という人間中で一番獰悪な種族であったそうだ。この書生というのは時々我々を捕えて煮て食うという話である。しかしその当時は何という考もなかったから別段恐しいとも思わなかった。ただ彼の掌に載せられてスーと持ち上げられた時何だかフワフワした感じがあったばかりである。掌の上で少し落ちついて書生の顔を見たのがいわゆる人間というものの見始であろう。この時妙なものだと思った感じが今でも残っている。第一毛をもって装飾されべきはずの顔がつるつるしてまるで薬缶だ。その後猫にもだいぶ逢ったがこんな片輪には一度も出会わした事がない。のみならず顔の真中があまりに突起している。そうしてその穴の中から時々ぷうぷうと煙を吹く。どうも咽せぽくて実に弱った。これが人間の飲む煙草というものである事はようやくこの頃知った。\"\"\"\n",
    "\n",
    "message = [\n",
    "    system_prompt,\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": nekodearu\n",
    "    }\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    message, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "outputs = llm.generate(prompt, sampling_params)\n",
    "result = outputs[0].outputs[0].text.strip()\n",
    "\n",
    "print(\"解答:\", result)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "解答: この文章のトークン数は、**324**です。\n",
    "\n",
    "トークンは、単語や句読点など、文章の要素を表す最小単位です。\n",
    "\n",
    "この文章では、単語の分割や句読点の扱いによって、トークン数が変化する可能性があります。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp100-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}