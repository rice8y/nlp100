
<!DOCTYPE html>


<html lang="unknown" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>第10章: 事前学習済み言語モデル (GPT型) &#8212; NLP 100 Exercise</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css?v=4c969af8" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css?v=b4b7a797" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../../_static/documentation_options.js?v=f3cbe567"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=7f8ff830"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../../_static/tabs.js?v=3ee01567"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'docs/ch10/ch10';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="canonical" href="https://rice8y.github.io/nlp100/docs/ch10/ch10.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="prev" title="第9章: 事前学習済み言語モデル (BERT型)" href="../ch09/ch09.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="unknown"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="NLP 100 Exercise - Home"/>
    <img src="../../_static/logo.png" class="logo__image only-dark pst-js-only" alt="NLP 100 Exercise - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    言語処理100本ノック
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../ch01/ch01.html">第1章: 準備運動</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch02/ch02.html">第2章: UNIXコマンド</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch03/ch03.html">第3章: 正規表現</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch04/ch04.html">第4章: 形態素解析</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch05/ch05.html">第5章: 大規模言語モデル</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch06/ch06.html">第6章: 単語ベクトル</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch07/ch07.html">第7章: 機械学習</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch08/ch08.html">第8章: ニューラルネット</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch09/ch09.html">第9章: 事前学習済み言語モデル (BERT型)</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">第10章: 事前学習済み言語モデル (GPT型)</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/rice8y/nlp100/blob/main/docs/ch10/ch10.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/rice8y/nlp100" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/rice8y/nlp100/edit/main/docs/ch10/ch10.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/rice8y/nlp100/issues/new?title=Issue%20on%20page%20%2Fdocs/ch10/ch10.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/docs/ch10/ch10.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>第10章: 事前学習済み言語モデル (GPT型)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">90. 次単語予測</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">91. 続きのテキストの予測</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">92. 予測されたテキストの確率を計算</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">93. パープレキシティ</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">94. チャットテンプレート</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">95. マルチターンのチャット</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">96. プロンプトによる感情分析</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">97. 埋め込みに基づく感情分析</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">98. ファインチューニング</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">99. 選好チューニング</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="gpt">
<h1>第10章: 事前学習済み言語モデル (GPT型)<a class="headerlink" href="#gpt" title="Link to this heading">#</a></h1>
<p>本章では, GPT型 (Transformerのデコーダ型) の事前学習済みモデルを利用して, 言語生成, 評判分析器 (ポジネガ分類器) の構築, ファインチューニング, 強化学習などに取り組む.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>本章は, <code class="docutils literal notranslate"><span class="pre">code-cell</span></code> ではなく, Markdown のコードブロック内にコードを記述しているため, Google Colab上で直接実行できません.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>ToDo:</strong> 98, 99は<code class="docutils literal notranslate"><span class="pre">gpt2-medium</span></code>から<code class="docutils literal notranslate"><span class="pre">HuggingFaceH4/zephyr-7b-beta</span></code>に変更する.</p>
</div>
<section id="id1">
<h2>90. 次単語予測<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<p>&quot;The movie was full of&quot;に続くトークン (トークン列ではなく一つのトークンであることに注意せよ) として適切なもの上位10個と, その確率 (尤度) を求めよ.ただし, 言語モデルへのプロンプトがどのようなトークン列に変換されたか, 確認せよ.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">GPT2Tokenizer</span><span class="p">,</span> <span class="n">GPT2LMHeadModel</span><span class="p">,</span> <span class="n">set_seed</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>

<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;gpt2-medium&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">GPT2Tokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GPT2LMHeadModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>

<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;The movie was full of&quot;</span>
<span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">logits</span>

<span class="n">next_token_logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">next_token_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">k</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">top_probs</span><span class="p">,</span> <span class="n">top_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
    <span class="n">decoded_text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">([</span><span class="n">top_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">decoded_text</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">top_probs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="w"> </span>great:<span class="w"> </span><span class="m">0</span>.02309427782893181
<span class="w"> </span>references:<span class="w"> </span><span class="m">0</span>.013511945493519306
<span class="w"> </span>action:<span class="w"> </span><span class="m">0</span>.013043278828263283
<span class="w"> </span>moments:<span class="w"> </span><span class="m">0</span>.012449497357010841
<span class="w"> </span>the:<span class="w"> </span><span class="m">0</span>.01186001393944025
<span class="w"> </span>characters:<span class="w"> </span><span class="m">0</span>.008720042183995247
<span class="w"> </span>these:<span class="w"> </span><span class="m">0</span>.007216328755021095
<span class="w"> </span>surprises:<span class="w"> </span><span class="m">0</span>.006894332356750965
<span class="w"> </span>fun:<span class="w"> </span><span class="m">0</span>.006525978911668062
<span class="w"> </span>them:<span class="w"> </span><span class="m">0</span>.006154114380478859
</pre></div>
</div>
</section>
<section id="id2">
<h2>91. 続きのテキストの予測<a class="headerlink" href="#id2" title="Link to this heading">#</a></h2>
<p>&quot;The movie was full of&quot;に続くテキストを複数予測せよ.このとき, デコーディングの方法や温度パラメータ (temperature) を変えながら, 予測される複数のテキストの変化を観察せよ.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span><span class="p">,</span> <span class="n">set_seed</span>

<span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="n">generator</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s1">&#39;text-generation&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s1">&#39;gpt2-medium&#39;</span><span class="p">)</span>

<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;The movie was full of&quot;</span>

<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]:</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">num_return_sequences</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="n">t</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Temp=</span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;generated_text&quot;</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">Temp</span><span class="o">=</span><span class="m">0</span>.2:<span class="w"> </span>The<span class="w"> </span>movie<span class="w"> </span>was<span class="w"> </span>full<span class="w"> </span>of<span class="w"> </span>great<span class="w"> </span>moments,<span class="w"> </span>but<span class="w"> </span>it<span class="w"> </span>was<span class="w"> </span>also<span class="w"> </span>a<span class="w"> </span>bit<span class="w"> </span>of<span class="w"> </span>a<span class="w"> </span>letdown.<span class="w"> </span>The<span class="w"> </span>film<span class="w"> </span>was<span class="w"> </span>a<span class="w"> </span>bit<span class="w"> </span>of<span class="w"> </span>a<span class="w"> </span>letdown.

Setting<span class="w"> </span><span class="sb">`</span>pad_token_id<span class="sb">`</span><span class="w"> </span>to<span class="w"> </span><span class="sb">`</span>eos_token_id<span class="sb">`</span>:50256<span class="w"> </span><span class="k">for</span><span class="w"> </span>open-end<span class="w"> </span>generation.
<span class="nv">Temp</span><span class="o">=</span><span class="m">0</span>.4:<span class="w"> </span>The<span class="w"> </span>movie<span class="w"> </span>was<span class="w"> </span>full<span class="w"> </span>of<span class="w"> </span>action<span class="w"> </span>sequences<span class="w"> </span>that<span class="w"> </span>were<span class="w"> </span>very<span class="w"> </span>exciting<span class="w"> </span>to<span class="w"> </span>watch.<span class="w"> </span>The<span class="w"> </span>movie<span class="w"> </span>was<span class="w"> </span>very<span class="w"> </span>well<span class="w"> </span><span class="k">done</span>,<span class="w"> </span>and<span class="w"> </span>I<span class="w"> </span>think<span class="w"> </span>it<span class="w"> </span>was<span class="w"> </span>a<span class="w"> </span>great<span class="w"> </span>movie.
Setting<span class="w"> </span><span class="sb">`</span>pad_token_id<span class="sb">`</span><span class="w"> </span>to<span class="w"> </span><span class="sb">`</span>eos_token_id<span class="sb">`</span>:50256<span class="w"> </span><span class="k">for</span><span class="w"> </span>open-end<span class="w"> </span>generation.
<span class="nv">Temp</span><span class="o">=</span><span class="m">0</span>.7:<span class="w"> </span>The<span class="w"> </span>movie<span class="w"> </span>was<span class="w"> </span>full<span class="w"> </span>of<span class="w"> </span>all<span class="w"> </span>the<span class="w"> </span>things<span class="w"> </span>I<span class="w"> </span>love<span class="w"> </span>about<span class="w"> </span>this<span class="w"> </span>country:<span class="w"> </span>the<span class="w"> </span>rich,<span class="w"> </span>the<span class="w"> </span>black,<span class="w"> </span>the<span class="w"> </span>working<span class="w"> </span>class,<span class="s2">&quot; said D&#39;Amato.</span>
<span class="s2">Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.</span>
<span class="s2">Temp=0.9: The movie was full of action and violence. The scene in the prison in which Lee and Davis are talking and the scene in which Lee kills John,</span>
</pre></div>
</div>
</section>
<section id="id3">
<h2>92. 予測されたテキストの確率を計算<a class="headerlink" href="#id3" title="Link to this heading">#</a></h2>
<p>&quot;The movie was full of&quot;に続くテキストを予測し, 生成された各単語の尤度を表示せよ (生成されるテキストが長いと出力が読みにくくなるので, 適当な長さで生成を打ち切るとよい) .</p>
</section>
<section id="id4">
<h2>93. パープレキシティ<a class="headerlink" href="#id4" title="Link to this heading">#</a></h2>
<p>適当な文を準備して, 事前学習済み言語モデルでパープレキシティを測定せよ.例えば,</p>
<ul class="simple">
<li><p>The movie was full of surprises</p></li>
<li><p>The movies were full of surprises</p></li>
<li><p>The movie were full of surprises</p></li>
<li><p>The movies was full of surprises</p></li>
</ul>
<p>の4文に対して, パープレキシティを測定して観察せよ (最後の2つの文は故意に文法的な間違いを入れた).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">GPT2Tokenizer</span><span class="p">,</span> <span class="n">GPT2LMHeadModel</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">math</span>

<span class="k">def</span> <span class="nf">calc_ppl</span><span class="p">(</span><span class="n">sentences</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span>
    <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">logits</span>
        
    <span class="n">shift_logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
    <span class="n">shift_labels</span> <span class="o">=</span> <span class="n">input_ids</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>

    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">shift_logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">shift_logits</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">shift_labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;gpt2-medium&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">GPT2Tokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GPT2LMHeadModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>

<span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>

<span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;The movie was full of surprises&quot;</span><span class="p">,</span>
    <span class="s2">&quot;The movies were full of surprises&quot;</span><span class="p">,</span>
    <span class="s2">&quot;The movie were full of surprises&quot;</span><span class="p">,</span>
    <span class="s2">&quot;The movies was full of surprises&quot;</span>
<span class="p">]</span>

<span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">sentence</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">calc_ppl</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>The<span class="w"> </span>movie<span class="w"> </span>was<span class="w"> </span>full<span class="w"> </span>of<span class="w"> </span>surprises:<span class="w"> </span><span class="m">89</span>.45385588749441
The<span class="w"> </span>movies<span class="w"> </span>were<span class="w"> </span>full<span class="w"> </span>of<span class="w"> </span>surprises:<span class="w"> </span><span class="m">164</span>.8886480442875
The<span class="w"> </span>movie<span class="w"> </span>were<span class="w"> </span>full<span class="w"> </span>of<span class="w"> </span>surprises:<span class="w"> </span><span class="m">324</span>.1063371099563
The<span class="w"> </span>movies<span class="w"> </span>was<span class="w"> </span>full<span class="w"> </span>of<span class="w"> </span>surprises:<span class="w"> </span><span class="m">388</span>.4464576262505
</pre></div>
</div>
</section>
<section id="id5">
<h2>94. チャットテンプレート<a class="headerlink" href="#id5" title="Link to this heading">#</a></h2>
<p>&quot;What do you call a sweet eaten after dinner?&quot;という問いかけに対する応答を生成するため, チャットテンプレートを適用し, 言語モデルに与えるべきプロンプトを作成せよ.また, そのプロンプトに対する応答を生成し, 表示せよ.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">set_seed</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>    
    
<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;HuggingFaceH4/zephyr-7b-beta&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>

<span class="n">chat</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;You are an excellent assistant.&quot;</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;What do you call a sweet eaten after dinner?&quot;</span><span class="p">}</span>
<span class="p">]</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">chat</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">add_generate_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
        <span class="o">**</span><span class="n">inputs</span><span class="p">,</span>
        <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
        <span class="n">do_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
        <span class="n">top_p</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
        <span class="n">pad_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
    <span class="p">)</span>

<span class="n">generated_text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">generated_text</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>&lt;<span class="p">|</span>system<span class="p">|</span>&gt;
You<span class="w"> </span>are<span class="w"> </span>an<span class="w"> </span>excellent<span class="w"> </span>assistant.
&lt;<span class="p">|</span>user<span class="p">|</span>&gt;
What<span class="w"> </span><span class="k">do</span><span class="w"> </span>you<span class="w"> </span>call<span class="w"> </span>a<span class="w"> </span>sweet<span class="w"> </span>eaten<span class="w"> </span>after<span class="w"> </span>dinner?
&lt;<span class="p">|</span>assistant<span class="p">|</span>&gt;
A<span class="w"> </span>dessert<span class="w"> </span>or<span class="w"> </span>a<span class="w"> </span>dessert<span class="w"> </span>item,<span class="w"> </span>such<span class="w"> </span>as<span class="w"> </span>cake,<span class="w"> </span>pie,<span class="w"> </span>cookies,<span class="w"> </span>ice<span class="w"> </span>cream,<span class="w"> </span>or<span class="w"> </span>fruit<span class="w"> </span>with<span class="w"> </span>a<span class="w"> </span>sweet<span class="w"> </span>sauce.<span class="w"> </span>The<span class="w"> </span>specific<span class="w"> </span>term<span class="w"> </span>may<span class="w"> </span>vary<span class="w"> </span>based<span class="w"> </span>on<span class="w"> </span>the<span class="w"> </span><span class="nb">type</span><span class="w"> </span>of<span class="w"> </span>sweet<span class="w"> </span>being<span class="w"> </span>referred<span class="w"> </span>to.
</pre></div>
</div>
</section>
<section id="id6">
<h2>95. マルチターンのチャット<a class="headerlink" href="#id6" title="Link to this heading">#</a></h2>
<p>問題94で生成された応答に対して, 追加で&quot;Please give me the plural form of the word with its spelling in reverse order.&quot;と問いかけたときの応答を生成・表示せよ.また, その時に言語モデルに与えるプロンプトを確認せよ.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">set_seed</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>  

<span class="k">def</span> <span class="nf">generate_text</span><span class="p">(</span><span class="n">prompt</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
            <span class="o">**</span><span class="n">inputs</span><span class="p">,</span>
            <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
            <span class="n">do_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
            <span class="n">top_p</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
            <span class="n">pad_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
        <span class="p">)</span>
    
    <span class="k">return</span> <span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">extract_assistant_reply</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;&lt;|assistant|&gt;&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">text</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;HuggingFaceH4/zephyr-7b-beta&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>

<span class="n">chat</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;You are an excellent assistant.&quot;</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;What do you call a sweet eaten after dinner?&quot;</span><span class="p">}</span>
<span class="p">]</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">chat</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">add_generate_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">raw_text</span> <span class="o">=</span> <span class="n">generate_text</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
<span class="n">decoded_text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">raw_text</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">chat</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;assistant&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">extract_assistant_reply</span><span class="p">(</span><span class="n">decoded_text</span><span class="p">)})</span>
<span class="n">chat</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Please give me the plural form of the word with its spelling in reverse order.&quot;</span><span class="p">})</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">chat</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">add_generate_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">raw_text</span> <span class="o">=</span> <span class="n">generate_text</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
<span class="n">decoded_text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">raw_text</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">decoded_text</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>&lt;<span class="p">|</span>system<span class="p">|</span>&gt;
You<span class="w"> </span>are<span class="w"> </span>an<span class="w"> </span>excellent<span class="w"> </span>assistant.
&lt;<span class="p">|</span>user<span class="p">|</span>&gt;
What<span class="w"> </span><span class="k">do</span><span class="w"> </span>you<span class="w"> </span>call<span class="w"> </span>a<span class="w"> </span>sweet<span class="w"> </span>eaten<span class="w"> </span>after<span class="w"> </span>dinner?
&lt;<span class="p">|</span>assistant<span class="p">|</span>&gt;
A<span class="w"> </span>dessert<span class="w"> </span>or<span class="w"> </span>a<span class="w"> </span>dessert<span class="w"> </span>item,<span class="w"> </span>such<span class="w"> </span>as<span class="w"> </span>cake,<span class="w"> </span>pie,<span class="w"> </span>cookies,<span class="w"> </span>ice<span class="w"> </span>cream,<span class="w"> </span>or<span class="w"> </span>fruit<span class="w"> </span>with<span class="w"> </span>a<span class="w"> </span>sweet<span class="w"> </span>sauce.<span class="w"> </span>The<span class="w"> </span>specific<span class="w"> </span>term<span class="w"> </span>may<span class="w"> </span>vary<span class="w"> </span>based<span class="w"> </span>on<span class="w"> </span>the<span class="w"> </span><span class="nb">type</span><span class="w"> </span>of<span class="w"> </span>sweet<span class="w"> </span>being<span class="w"> </span>referred<span class="w"> </span>to.
&lt;<span class="p">|</span>user<span class="p">|</span>&gt;
Please<span class="w"> </span>give<span class="w"> </span>me<span class="w"> </span>the<span class="w"> </span>plural<span class="w"> </span>form<span class="w"> </span>of<span class="w"> </span>the<span class="w"> </span>word<span class="w"> </span>with<span class="w"> </span>its<span class="w"> </span>spelling<span class="w"> </span><span class="k">in</span><span class="w"> </span>reverse<span class="w"> </span>order.
&lt;<span class="p">|</span>assistant<span class="p">|</span>&gt;
If<span class="w"> </span>the<span class="w"> </span>word<span class="w"> </span>ends<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="s2">&quot;s,&quot;</span><span class="w"> </span>simply<span class="w"> </span>add<span class="w"> </span>an<span class="w"> </span><span class="s2">&quot;es&quot;</span><span class="w"> </span>to<span class="w"> </span>the<span class="w"> </span>end.<span class="w"> </span>However,<span class="w"> </span><span class="k">if</span><span class="w"> </span>the<span class="w"> </span>word<span class="w"> </span>ends<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="s2">&quot;ch,&quot;</span><span class="w"> </span><span class="s2">&quot;sh,&quot;</span><span class="w"> </span><span class="s2">&quot;x,&quot;</span><span class="w"> </span>or<span class="w"> </span><span class="s2">&quot;s&quot;</span><span class="w"> </span>preceded<span class="w"> </span>by<span class="w"> </span>a<span class="w"> </span>consonant,<span class="w"> </span>you<span class="w"> </span>add<span class="w"> </span><span class="s2">&quot;es&quot;</span><span class="w"> </span>and<span class="w"> </span>change<span class="w"> </span>the<span class="w"> </span><span class="s2">&quot;s&quot;</span><span class="w"> </span>to<span class="w"> </span><span class="s2">&quot;es&quot;</span><span class="w"> </span>as<span class="w"> </span>well.<span class="w"> </span>For<span class="w"> </span>example:

-<span class="w"> </span>Churches<span class="w"> </span><span class="o">(</span>churches<span class="o">)</span>
-<span class="w"> </span>Boxes<span class="w"> </span><span class="o">(</span>boxes<span class="o">)</span>
-Ches<span class="w"> </span><span class="o">(</span>chess<span class="o">)</span>
-Kisses<span class="w"> </span><span class="o">(</span>kisses<span class="o">)</span>

In<span class="w"> </span>reverse<span class="w"> </span>order,<span class="w"> </span>the<span class="w"> </span>plural<span class="w"> </span>forms<span class="w"> </span>would<span class="w"> </span>be:

-<span class="w"> </span>Esreuq<span class="w"> </span>siht<span class="w"> </span>noitavT<span class="w"> </span><span class="o">(</span>desserts<span class="o">)</span>
-<span class="w"> </span>EttorC<span class="w"> </span>siht<span class="w"> </span>noitavT<span class="w"> </span><span class="o">(</span>cookies<span class="o">)</span>
-<span class="w"> </span>EhT<span class="w"> </span>roE<span class="w"> </span>siht<span class="w"> </span>noitavT<span class="w"> </span><span class="o">(</span>cakes<span class="o">)</span>
-<span class="w"> </span>EhT<span class="w"> </span>roE<span class="w"> </span>siht<span class="w"> </span>noitavT<span class="w"> </span><span class="o">(</span>pies<span class="o">)</span>
-<span class="w"> </span>EhT<span class="w"> </span>roE<span class="w"> </span>siht<span class="w"> </span>noitavT<span class="w"> </span><span class="o">(</span>ice<span class="w"> </span>cream<span class="o">)</span>
-<span class="w"> </span>EhT<span class="w"> </span>roE<span class="w"> </span>siht<span class="w"> </span>noitavT<span class="w"> </span><span class="o">(</span>fruit<span class="o">)</span>
-<span class="w"> </span>EhT<span class="w"> </span>roE<span class="w"> </span>siht<span class="w"> </span>noitavT<span class="w"> </span><span class="o">(</span>sauces<span class="o">)</span>

Note:<span class="w"> </span>The<span class="w"> </span>reverse<span class="w"> </span>spelling<span class="w"> </span>is<span class="w"> </span>just<span class="w"> </span><span class="k">for</span><span class="w"> </span>fun<span class="w"> </span>and<span class="w"> </span>is<span class="w"> </span>not<span class="w"> </span>a<span class="w"> </span>commonly<span class="w"> </span>used<span class="w"> </span>method<span class="w"> </span><span class="k">for</span><span class="w"> </span>spelling<span class="w"> </span>words<span class="w"> </span><span class="k">in</span><span class="w"> </span>English.
</pre></div>
</div>
</section>
<section id="id7">
<h2>96. プロンプトによる感情分析<a class="headerlink" href="#id7" title="Link to this heading">#</a></h2>
<p>事前学習済み言語モデルで感情分析を行いたい.テキストを含むプロンプトを事前学習済み言語モデルに与え, (ファインチューニングは行わずに) テキストのポジネガを予測するという戦略で, <a class="reference external" href="https://dl.fbaipublicfiles.com/glue/data/SST-2.zip">SST-2</a>の開発データにおける正解率を測定せよ.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">set_seed</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="k">def</span> <span class="nf">generate_text</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
            <span class="o">**</span><span class="n">inputs</span><span class="p">,</span>
            <span class="n">max_new_tokens</span><span class="o">=</span><span class="n">max_new_tokens</span><span class="p">,</span>
            <span class="n">do_sample</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">pad_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>
        <span class="p">)</span>
    
    <span class="k">return</span> <span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">extract_assistant_reply</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">text</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">generate_examples</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">):</span>
    <span class="n">pos_examples</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
    <span class="n">neg_examples</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
    <span class="n">examples</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">pos_examples</span><span class="p">[</span><span class="s2">&quot;sentence&quot;</span><span class="p">],</span> <span class="n">pos_examples</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]))</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">neg_examples</span><span class="p">[</span><span class="s2">&quot;sentence&quot;</span><span class="p">],</span> <span class="n">neg_examples</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]))</span>
    
    <span class="n">prompt</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">sentence</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">:</span>
        <span class="n">prompt</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">sentence</span><span class="p">})</span>
        <span class="n">prompt</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;assistant&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">label</span><span class="p">)})</span>
        
    <span class="k">return</span> <span class="n">prompt</span>

<span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>

<span class="n">train_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="s2">&quot;../ch07/SST-2/train.tsv&quot;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">dev_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="s2">&quot;../ch07/SST-2/dev.tsv&quot;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;HuggingFaceH4/zephyr-7b-beta&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="n">model_name</span><span class="p">,</span>
    <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span>
    <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span>
<span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="s2">&quot;&lt;|assistant|&gt;</span><span class="se">\n</span><span class="s2">1&quot;</span><span class="p">)</span>
<span class="n">max_tokens</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">device</span>

<span class="n">preds</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">valid_labels</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">skipped_count</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">examples</span> <span class="o">=</span> <span class="n">generate_examples</span><span class="p">(</span><span class="n">train_df</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dev_df</span><span class="p">)),</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Progress&quot;</span><span class="p">):</span>
    <span class="n">chat</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;You are a professional in emotional analysis. Please judge the following sentences positively or negatively. If it is positive, output 1, if it is negative, output 0.&quot;</span><span class="p">},</span>
        <span class="o">*</span><span class="n">examples</span><span class="p">,</span>
        <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">dev_df</span><span class="p">[</span><span class="s2">&quot;sentence&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">]}</span>
    <span class="p">]</span>

    <span class="n">prompt</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">chat</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">add_generate_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">raw_output</span> <span class="o">=</span> <span class="n">generate_text</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">max_tokens</span><span class="p">)</span>
    <span class="n">decoded_text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">raw_output</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">extract_assistant_reply</span><span class="p">(</span><span class="n">decoded_text</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">pred</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;0&quot;</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">}:</span>
        <span class="n">preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span>
        <span class="n">valid_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">dev_df</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">]))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">skipped_count</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">valid_labels</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Acc: </span><span class="si">{</span><span class="n">acc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Skipped samples: </span><span class="si">{</span><span class="n">skipped_count</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Acc:<span class="w"> </span><span class="m">0</span>.9380733944954128
Skipped<span class="w"> </span>samples:<span class="w"> </span><span class="m">0</span>
</pre></div>
</div>
</section>
<section id="id8">
<h2>97. 埋め込みに基づく感情分析<a class="headerlink" href="#id8" title="Link to this heading">#</a></h2>
<p>事前学習済み言語モデルでテキストをベクトルで表現 (エンコード) し, そのベクトルにフィードフォワード層を通すことで極性ラベルを予測するモデルを学習せよ.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">GPT2Model</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">Dataset</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">):</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="n">set_seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>

<span class="n">train_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="s2">&quot;../ch07/SST-2/train.tsv&quot;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">dev_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="s2">&quot;../ch07/SST-2/dev.tsv&quot;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">SSTDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataframe</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">dataframe</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_length</span> <span class="o">=</span> <span class="n">max_length</span>
        
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="n">sentence</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">&#39;sentence&#39;</span><span class="p">]</span>
        <span class="n">label</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s1">&#39;label&#39;</span><span class="p">])</span>
        
        <span class="n">encoding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
            <span class="n">sentence</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_length</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;max_length&#39;</span><span class="p">,</span>
            <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="s1">&#39;pt&#39;</span>
        <span class="p">)</span>
        
        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;input_ids&#39;</span><span class="p">:</span> <span class="n">encoding</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span>
            <span class="s1">&#39;attention_mask&#39;</span><span class="p">:</span> <span class="n">encoding</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span>
            <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
        <span class="p">}</span>

<span class="k">class</span> <span class="nc">SentimentClassifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SentimentClassifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">GPT2Model</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;gpt2-medium&quot;</span><span class="p">)</span>
        <span class="n">hidden_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">n_embd</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
        <span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">):</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
        <span class="n">last_hidden_states</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">last_hidden_state</span>
        <span class="n">sequence_lengths</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">selected_hidden_states</span> <span class="o">=</span> <span class="n">last_hidden_states</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">batch_size</span><span class="p">),</span> <span class="n">sequence_lengths</span><span class="p">]</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">selected_hidden_states</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logits</span>

<span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
    
    <span class="n">best_val_accuracy</span> <span class="o">=</span> <span class="mf">0.0</span>
    
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2"> [Train]&quot;</span><span class="p">):</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            
            <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            
        <span class="n">train_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>

        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">val_preds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">val_true</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">val_loader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2"> [Val]&quot;</span><span class="p">):</span>
                <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                
                <span class="n">val_preds</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">preds</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
                <span class="n">val_true</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
        
        <span class="n">val_accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">val_true</span><span class="p">,</span> <span class="n">val_preds</span><span class="p">)</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">, Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Val Accuracy: </span><span class="si">{</span><span class="n">val_accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">val_accuracy</span> <span class="o">&gt;</span> <span class="n">best_val_accuracy</span><span class="p">:</span>
            <span class="n">best_val_accuracy</span> <span class="o">=</span> <span class="n">val_accuracy</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s2">&quot;best_gpt2_medium_sentiment_model.pt&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model saved with accuracy: </span><span class="si">{</span><span class="n">best_val_accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">best_val_accuracy</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;gpt2-medium&quot;</span><span class="p">)</span>
    <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>

    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">SSTDataset</span><span class="p">(</span><span class="n">train_df</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">)</span>
    <span class="n">val_dataset</span> <span class="o">=</span> <span class="n">SSTDataset</span><span class="p">(</span><span class="n">dev_df</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">)</span>

    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">SentimentClassifier</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">best_accuracy</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training completed with best validation accuracy: </span><span class="si">{</span><span class="n">best_accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>

</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Epoch</span> <span class="mi">1</span><span class="o">/</span><span class="mi">3</span> <span class="p">[</span><span class="n">Train</span><span class="p">]:</span> <span class="mi">100</span><span class="o">%|</span><span class="err">███████████████████████████████████████████████████████████████████████████████████████████████</span><span class="o">|</span> <span class="mi">2105</span><span class="o">/</span><span class="mi">2105</span> <span class="p">[</span><span class="mi">36</span><span class="p">:</span><span class="mi">21</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span>  <span class="mf">1.04</span><span class="n">s</span><span class="o">/</span><span class="n">it</span><span class="p">]</span>
<span class="n">Epoch</span> <span class="mi">1</span><span class="o">/</span><span class="mi">3</span> <span class="p">[</span><span class="n">Val</span><span class="p">]:</span> <span class="mi">100</span><span class="o">%|</span><span class="err">█████████████████████████████████████████████████████████████████████████████████████████████████████</span><span class="o">|</span> <span class="mi">28</span><span class="o">/</span><span class="mi">28</span> <span class="p">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">09</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span>  <span class="mf">3.01</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span>
<span class="n">Epoch</span> <span class="mi">1</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span> <span class="n">Train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2461</span><span class="p">,</span> <span class="n">Val</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">0.9300</span>
<span class="n">Model</span> <span class="n">saved</span> <span class="k">with</span> <span class="n">accuracy</span><span class="p">:</span> <span class="mf">0.9300</span>
<span class="n">Epoch</span> <span class="mi">2</span><span class="o">/</span><span class="mi">3</span> <span class="p">[</span><span class="n">Train</span><span class="p">]:</span> <span class="mi">100</span><span class="o">%|</span><span class="err">███████████████████████████████████████████████████████████████████████████████████████████████</span><span class="o">|</span> <span class="mi">2105</span><span class="o">/</span><span class="mi">2105</span> <span class="p">[</span><span class="mi">35</span><span class="p">:</span><span class="mi">58</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span>  <span class="mf">1.03</span><span class="n">s</span><span class="o">/</span><span class="n">it</span><span class="p">]</span>
<span class="n">Epoch</span> <span class="mi">2</span><span class="o">/</span><span class="mi">3</span> <span class="p">[</span><span class="n">Val</span><span class="p">]:</span> <span class="mi">100</span><span class="o">%|</span><span class="err">█████████████████████████████████████████████████████████████████████████████████████████████████████</span><span class="o">|</span> <span class="mi">28</span><span class="o">/</span><span class="mi">28</span> <span class="p">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">09</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span>  <span class="mf">3.03</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span>
<span class="n">Epoch</span> <span class="mi">2</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span> <span class="n">Train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1375</span><span class="p">,</span> <span class="n">Val</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">0.9358</span>
<span class="n">Model</span> <span class="n">saved</span> <span class="k">with</span> <span class="n">accuracy</span><span class="p">:</span> <span class="mf">0.9358</span>
<span class="n">Epoch</span> <span class="mi">3</span><span class="o">/</span><span class="mi">3</span> <span class="p">[</span><span class="n">Train</span><span class="p">]:</span> <span class="mi">100</span><span class="o">%|</span><span class="err">███████████████████████████████████████████████████████████████████████████████████████████████</span><span class="o">|</span> <span class="mi">2105</span><span class="o">/</span><span class="mi">2105</span> <span class="p">[</span><span class="mi">35</span><span class="p">:</span><span class="mi">38</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span>  <span class="mf">1.02</span><span class="n">s</span><span class="o">/</span><span class="n">it</span><span class="p">]</span>
<span class="n">Epoch</span> <span class="mi">3</span><span class="o">/</span><span class="mi">3</span> <span class="p">[</span><span class="n">Val</span><span class="p">]:</span> <span class="mi">100</span><span class="o">%|</span><span class="err">█████████████████████████████████████████████████████████████████████████████████████████████████████</span><span class="o">|</span> <span class="mi">28</span><span class="o">/</span><span class="mi">28</span> <span class="p">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">09</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span>  <span class="mf">3.03</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span>
<span class="n">Epoch</span> <span class="mi">3</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span> <span class="n">Train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1015</span><span class="p">,</span> <span class="n">Val</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">0.9369</span>
<span class="n">Model</span> <span class="n">saved</span> <span class="k">with</span> <span class="n">accuracy</span><span class="p">:</span> <span class="mf">0.9369</span>
<span class="n">Training</span> <span class="n">completed</span> <span class="k">with</span> <span class="n">best</span> <span class="n">validation</span> <span class="n">accuracy</span><span class="p">:</span> <span class="mf">0.9369</span>
</pre></div>
</div>
</section>
<section id="id9">
<h2>98. ファインチューニング<a class="headerlink" href="#id9" title="Link to this heading">#</a></h2>
<p>問題96のプロンプトに対して, 正解の感情ラベルをテキストの応答として返すように事前学習済みモデルをファインチューニングせよ.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">Trainer</span><span class="p">,</span> <span class="n">TrainingArguments</span><span class="p">,</span> <span class="n">DataCollatorForLanguageModeling</span><span class="p">,</span> <span class="n">set_seed</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
    <span class="n">full_texts</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;Sentence: &quot;</span> <span class="o">+</span> <span class="n">sentence</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Label: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">sentence</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">&quot;sentence&quot;</span><span class="p">],</span> <span class="n">examples</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">])</span>
    <span class="p">]</span>
    <span class="n">tokenized</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">full_texts</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
    
    <span class="n">labels</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">])</span>
    
    <span class="n">prompt_texts</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;Sentence: &quot;</span> <span class="o">+</span> <span class="n">sentence</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Label:&quot;</span> 
        <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">[</span><span class="s2">&quot;sentence&quot;</span><span class="p">]</span>
    <span class="p">]</span>
    <span class="n">prompt_tokenized</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">prompt_texts</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">prompt_ids</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">prompt_tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]):</span>
        <span class="n">prompt_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">prompt_ids</span><span class="p">)</span>
        <span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">][:</span><span class="n">prompt_len</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">100</span><span class="p">]</span> <span class="o">*</span> <span class="n">prompt_len</span>
    
    <span class="n">tokenized</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>
    <span class="k">return</span> <span class="n">tokenized</span>

<span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">training_args</span><span class="p">,</span> <span class="n">data_collator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_dir</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
        <span class="n">train_dataset</span><span class="o">=</span><span class="n">datasets</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span>
        <span class="n">eval_dataset</span><span class="o">=</span><span class="n">datasets</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">],</span>
        <span class="n">data_collator</span><span class="o">=</span><span class="n">data_collator</span>
    <span class="p">)</span>
    
    <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    
    <span class="k">if</span> <span class="n">output_dir</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>
        <span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">eval_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_return_sequences</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">input_texts</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;Sentence: </span><span class="si">{</span><span class="n">ex</span><span class="p">[</span><span class="s1">&#39;sentence&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">Label:&quot;</span> <span class="k">for</span> <span class="n">ex</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">]</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">ex</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">])</span> <span class="k">for</span> <span class="n">ex</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">]</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">input_text</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">input_texts</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Evaluating&quot;</span><span class="p">):</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">input_text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="n">max_new_tokens</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span> <span class="n">num_return_sequences</span><span class="o">=</span><span class="n">num_return_sequences</span><span class="p">)</span>
        <span class="n">generated_text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="n">skip_special_tokens</span><span class="p">,</span> <span class="n">eos_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">)</span>
        <span class="n">label_start</span> <span class="o">=</span> <span class="n">generated_text</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;Label:&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="s2">&quot;Label:&quot;</span><span class="p">)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">generated_text</span><span class="p">[</span><span class="n">label_start</span><span class="p">:]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
        
    <span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Acc: </span><span class="si">{</span><span class="n">acc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
    
<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;gpt2-medium&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;csv&quot;</span><span class="p">,</span> <span class="n">data_files</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="s2">&quot;../ch07/SST-2/train.tsv&quot;</span><span class="p">,</span> <span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="s2">&quot;../ch07/SST-2/dev.tsv&quot;</span><span class="p">},</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">tokenized_datasets</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;./results&quot;</span><span class="p">,</span>
    <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
    <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
    <span class="n">logging_dir</span><span class="o">=</span><span class="s2">&quot;./logs&quot;</span><span class="p">,</span>
    <span class="n">eval_accumulation_steps</span><span class="o">=</span><span class="mi">10</span>
<span class="p">)</span>
   
<span class="n">data_collator</span> <span class="o">=</span> <span class="n">DataCollatorForLanguageModeling</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">mlm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">model_output_dir</span> <span class="o">=</span> <span class="s2">&quot;./results/model&quot;</span>
    
<span class="n">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">datasets</span><span class="o">=</span><span class="n">tokenized_datasets</span><span class="p">,</span> <span class="n">training_args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span> <span class="n">data_collator</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span> <span class="n">output_dir</span><span class="o">=</span><span class="n">model_output_dir</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_output_dir</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_output_dir</span><span class="p">)</span>
   
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;csv&quot;</span><span class="p">,</span> <span class="n">data_files</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="s2">&quot;../ch07/SST-2/train.tsv&quot;</span><span class="p">,</span> <span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="s2">&quot;../ch07/SST-2/dev.tsv&quot;</span><span class="p">},</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">eval_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Acc:<span class="w"> </span><span class="m">0</span>.8635321100917431
</pre></div>
</div>
</section>
<section id="id10">
<h2>99. 選好チューニング<a class="headerlink" href="#id10" title="Link to this heading">#</a></h2>
<p>問題96のプロンプトに対して, 正解の感情ラベルを含むテキストを望ましい応答, 間違った感情ラベルを含むテキストを望ましくない応答として, 事前学習済み言語モデルを選好チューニング (preference tuning) を実施せよ.選好チューニングのアルゴリズムとしては, 近傍方策最適化 (PPO: Proximal Policy Optimization) や直接選好最適化 (DPO: Direct Preference Optimization) などが考えられる.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">set_seed</span>
<span class="kn">from</span> <span class="nn">trl</span> <span class="kn">import</span> <span class="n">DPOConfig</span><span class="p">,</span> <span class="n">DPOTrainer</span>
<span class="kn">from</span> <span class="nn">trl.trainer.utils</span> <span class="kn">import</span> <span class="n">DPODataCollatorWithPadding</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="n">set_seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
    <span class="n">tokenized_prompt</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">&quot;prompt&quot;</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
    <span class="n">tokenized_chosen</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">&quot;chosen&quot;</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
    <span class="n">tokenized_rejected</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">&quot;rejected&quot;</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;prompt_input_ids&quot;</span><span class="p">:</span> <span class="n">tokenized_prompt</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">],</span>
        <span class="s2">&quot;chosen_input_ids&quot;</span><span class="p">:</span> <span class="n">tokenized_chosen</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">],</span>
        <span class="s2">&quot;rejected_input_ids&quot;</span><span class="p">:</span> <span class="n">tokenized_rejected</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">],</span>
    <span class="p">}</span>

<span class="k">def</span> <span class="nf">make_pref_dataset</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
    <span class="n">records</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;prompt&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;chosen&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;rejected&quot;</span><span class="p">:</span> <span class="p">[]}</span>
    <span class="k">for</span> <span class="n">sent</span><span class="p">,</span> <span class="n">lbl</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">&quot;sentence&quot;</span><span class="p">],</span> <span class="n">examples</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]):</span>
        <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Sentence: </span><span class="si">{</span><span class="n">sent</span><span class="si">}</span><span class="se">\n</span><span class="s2">Label:&quot;</span>
        <span class="n">chosen</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">lbl</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">wrong_lbl</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">lbl</span>
        <span class="n">rejected</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">wrong_lbl</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">records</span><span class="p">[</span><span class="s2">&quot;prompt&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
        <span class="n">records</span><span class="p">[</span><span class="s2">&quot;chosen&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chosen</span><span class="p">)</span>
        <span class="n">records</span><span class="p">[</span><span class="s2">&quot;rejected&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rejected</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">records</span>

<span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">eval_dataset</span><span class="p">,</span> <span class="n">training_args</span><span class="p">,</span> <span class="n">data_collator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">compute_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_dir</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">DPOTrainer</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
        <span class="n">processing_class</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>
        <span class="n">eval_dataset</span><span class="o">=</span><span class="n">eval_dataset</span><span class="p">,</span>
    <span class="p">)</span>
    
    <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    
    <span class="k">if</span> <span class="n">output_dir</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>
        <span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">eval_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_return_sequences</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">input_texts</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;Sentence: </span><span class="si">{</span><span class="n">ex</span><span class="p">[</span><span class="s1">&#39;sentence&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">Label:&quot;</span> <span class="k">for</span> <span class="n">ex</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">]</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">ex</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">])</span> <span class="k">for</span> <span class="n">ex</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">]</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">input_text</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">input_texts</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Evaluating&quot;</span><span class="p">):</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">input_text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="n">max_new_tokens</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span> <span class="n">num_return_sequences</span><span class="o">=</span><span class="n">num_return_sequences</span><span class="p">)</span>
        <span class="n">generated_text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="n">skip_special_tokens</span><span class="p">,</span> <span class="n">eos_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">)</span>
        <span class="n">label_start</span> <span class="o">=</span> <span class="n">generated_text</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;Label:&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="s2">&quot;Label:&quot;</span><span class="p">)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">generated_text</span><span class="p">[</span><span class="n">label_start</span><span class="p">:]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
        
    <span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Acc: </span><span class="si">{</span><span class="n">acc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;gpt2-medium&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
<span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
       
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;csv&quot;</span><span class="p">,</span> <span class="n">data_files</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="s2">&quot;../ch07/SST-2/train.tsv&quot;</span><span class="p">,</span> <span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="s2">&quot;../ch07/SST-2/dev.tsv&quot;</span><span class="p">},</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">train_pref_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">make_pref_dataset</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">eval_pref_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">make_pref_dataset</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">training_args</span> <span class="o">=</span> <span class="n">DPOConfig</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;./dpo_results&quot;</span><span class="p">,</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
    <span class="n">save_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">&quot;steps&quot;</span><span class="p">,</span>
    <span class="n">eval_steps</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> 
    <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
    <span class="n">logging_dir</span><span class="o">=</span><span class="s1">&#39;./logs&#39;</span><span class="p">,</span>
    <span class="n">beta</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
    <span class="n">remove_unused_columns</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">disable_tqdm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">eval_accumulation_steps</span><span class="o">=</span><span class="mi">10</span>
<span class="p">)</span>

<span class="n">data_collator</span> <span class="o">=</span> <span class="n">DPODataCollatorWithPadding</span><span class="p">(</span>
    <span class="n">pad_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">,</span>
    <span class="n">label_pad_token_id</span><span class="o">=-</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">is_encoder_decoder</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="n">model_output_dir</span> <span class="o">=</span> <span class="s2">&quot;./results/model_dop&quot;</span>
        
<span class="n">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_pref_dataset</span><span class="p">,</span> <span class="n">eval_dataset</span><span class="o">=</span><span class="n">eval_pref_dataset</span><span class="p">,</span> <span class="n">training_args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span> <span class="n">data_collator</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span> <span class="n">output_dir</span><span class="o">=</span><span class="n">model_output_dir</span><span class="p">)</span>
 
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_output_dir</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_output_dir</span><span class="p">)</span>
        
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;csv&quot;</span><span class="p">,</span> <span class="n">data_files</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="s2">&quot;../ch07/SST-2/train.tsv&quot;</span><span class="p">,</span> <span class="s2">&quot;validation&quot;</span><span class="p">:</span> <span class="s2">&quot;../ch07/SST-2/dev.tsv&quot;</span><span class="p">},</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">eval_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Acc:<span class="w"> </span><span class="m">0</span>.9139908256880734
</pre></div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./docs/ch10"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../ch09/ch09.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">第9章: 事前学習済み言語モデル (BERT型)</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">90. 次単語予測</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">91. 続きのテキストの予測</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">92. 予測されたテキストの確率を計算</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">93. パープレキシティ</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">94. チャットテンプレート</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">95. マルチターンのチャット</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">96. プロンプトによる感情分析</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">97. 埋め込みに基づく感情分析</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">98. ファインチューニング</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">99. 選好チューニング</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Eito YONEYAMA
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <div>
<script src="https://utteranc.es/client.js"
repo="rice8y/nlp100"
issue-term="title"
label="💬"
theme="github-light"
crossorigin="anonymous"
async>
</script>
</div>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>