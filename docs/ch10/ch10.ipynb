{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第10章: 事前学習済み言語モデル (GPT型)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 90. 次単語予測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2-medium\")\n",
    "\n",
    "text = \"The movie was full of\"\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "    logits = outputs.logits\n",
    "\n",
    "next_token_logits = logits[0, -1]\n",
    "probs = torch.softmax(next_token_logits, dim=-1)\n",
    "\n",
    "k = 10\n",
    "top_probs, top_indices = torch.topk(probs, k)\n",
    "\n",
    "for i in range(k):\n",
    "    decoded_text = tokenizer.decode([top_indices[i]])\n",
    "    print(f\"{decoded_text}: {top_probs[i]}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    " great: 0.023094795644283295\n",
    " references: 0.013511938974261284\n",
    " action: 0.01304327230900526\n",
    " moments: 0.012449966743588448\n",
    " the: 0.01185955572873354\n",
    " characters: 0.008719970472157001\n",
    " these: 0.0072162700816988945\n",
    " surprises: 0.006894644349813461\n",
    " fun: 0.006525975652039051\n",
    " them: 0.006154205650091171\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 91. 続きのテキストの予測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from transformers import pipeline, set_seed\n",
    "set_seed(1234)\n",
    "\n",
    "generator = pipeline('text-generation', model='gpt2-medium')\n",
    "\n",
    "text = \"The movie was full of\"\n",
    "\n",
    "for t in [0.2, 0.4, 0.7, 0.9]:\n",
    "    outputs = generator(text, max_length=30, num_return_sequences=1, temperature=t)\n",
    "    print(f'Temp={t}: {outputs[0][\"generated_text\"]}')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "Temp=0.2: The movie was full of great moments, but it was also a bit of a letdown. The film was a bit of a letdown.\n",
    "\n",
    "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
    "Temp=0.4: The movie was full of action sequences that were very exciting to watch. The movie was very well done, and I think it was a great movie.\n",
    "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
    "Temp=0.7: The movie was full of all the things I love about this country: the rich, the black, the working class,\" said D'Amato.\n",
    "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
    "Temp=0.9: The movie was full of action and violence. The scene in the prison in which Lee and Davis are talking and the scene in which Lee kills John,\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 92."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
